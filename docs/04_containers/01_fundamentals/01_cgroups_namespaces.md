---
level: foundational
estimated_time: 50 min
prerequisites:
  - 01_foundations/01_virtualization_basics/01_the_ring0_problem.md
next_recommended:
  - 04_containers/01_fundamentals/02_union_filesystems.md
tags: [containers, linux, cgroups, namespaces, isolation, kernel]
---

# Linux Container Primitives: cgroups and Namespaces

**Learning Objectives:**
- Understand how Linux provides process isolation without hardware virtualization
- Explain the role of cgroups in resource limiting
- Identify the seven namespace types and their isolation boundaries
- Compare container isolation to VM isolation
- Recognize the security implications and limitations

---

## Introduction: Isolation Without Virtualization

In [The Ring-0 Problem](../../01_foundations/01_virtualization_basics/01_the_ring0_problem.md), we learned that **virtualization requires hardware support** because you can't run two operating systems in Ring 0 simultaneously. Virtual machines solve this with VT-x/AMD-V, creating two Ring-0 environments.

But what if you don't need **complete** isolation? What if you're okay with processes sharing the same kernel, as long as they:
- Can't see each other's processes
- Can't access each other's filesystems
- Can't exceed their allocated CPU/memory
- Can't interfere with each other's network

This is **container isolation**: using Linux kernel features to create isolated execution environments **without hardware virtualization**.

**The Two Pillars:**
1. **Namespaces** - Isolation (what you can see)
2. **cgroups** - Resource limits (what you can use)

---

## Part 1: Namespaces - Isolation

### What is a Namespace?

A namespace **wraps a global system resource** so that processes inside the namespace have their own isolated instance of that resource.

**Simple analogy:**
- **VM**: Separate house with its own kitchen, bedrooms, utilities
- **Namespace**: Separate apartment in the same building - own rooms, but shared building infrastructure

Processes in different namespaces **can't see** each other's resources, even though they're running on the same kernel.

### The Seven Namespace Types

Linux provides seven types of namespaces (as of kernel 5.6+):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NAMESPACE TYPE â”‚ ISOLATES                  â”‚ SINCE       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PID            â”‚ Process IDs               â”‚ Linux 2.6.24â”‚
â”‚ NET            â”‚ Network devices, stacks   â”‚ Linux 2.6.29â”‚
â”‚ MNT            â”‚ Mount points              â”‚ Linux 2.4.19â”‚
â”‚ UTS*           â”‚ Hostname & domain name    â”‚ Linux 2.6.19â”‚
â”‚ IPC            â”‚ Inter-process comm        â”‚ Linux 2.6.19â”‚
â”‚ USER           â”‚ User and group IDs        â”‚ Linux 3.8   â”‚
â”‚ CGROUP         â”‚ Cgroup hierarchy view     â”‚ Linux 4.6   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* UTS = UNIX Time-Sharing (historical name from UNIX Time-Sharing System)
```

Let's examine each in detail.

---

### PID Namespace: Process Isolation

**What it isolates:** Process ID numbers

```
Host System:
PID 1:    systemd (init)
PID 100:  sshd
PID 500:  containerized_app  â† Inside PID namespace

Inside Container's View (PID namespace):
PID 1:    containerized_app  â† Appears as PID 1!
PID 2:    child_process
```

**Key properties:**
- **First process in namespace gets PID 1** (appears as "init")
- Processes inside **cannot see** processes outside
- Processes outside **can see** processes inside (with different PIDs)
- Parent namespace has a "view" into child namespace

**Why this matters:**
- Container's main process thinks it's PID 1 (like in a VM)
- If PID 1 dies, all processes in namespace are killed
- Container can't see or signal host processes

**Example:**
```bash
# On host
$ ps aux | grep nginx
root     500  0.0  0.1  nginx: master

# Inside container
$ ps aux
PID   USER     COMMAND
1     root     nginx: master    â† Same process, different PID!
2     root     nginx: worker
```

---

### NET Namespace: Network Isolation

**What it isolates:** Network devices, IP addresses, routing tables, firewall rules

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Host Network Namespace                                  â”‚
â”‚ â”œâ”€ eth0 (192.168.1.100)                                â”‚
â”‚ â”œâ”€ lo (127.0.0.1)                                      â”‚
â”‚ â””â”€ Routing table, iptables rules                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ veth pair (virtual ethernet cable)
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Container Network Namespace                             â”‚
â”‚ â”œâ”€ eth0 (10.0.0.5) â† Different IP!                     â”‚
â”‚ â”œâ”€ lo (127.0.0.1)                                      â”‚
â”‚ â””â”€ Own routing table, iptables                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key properties:**
- Each namespace has its own:
  - Network interfaces (no `eth0` conflict)
  - IP addresses (can reuse 10.0.0.1 in multiple containers)
  - Routing tables
  - Firewall rules (iptables/nftables)
- Namespaces connected via **veth pairs** (virtual ethernet cables)

**What is a veth pair?**

A **veth (virtual ethernet) pair** acts like a virtual network cable connecting two network namespaces:
- Creates two connected network interfaces (both are kernel devices)
- One end typically placed in the container's namespace
- Other end stays in the host's namespace (attached to a bridge)
- Packets sent to one end immediately appear at the other end

**veth vs TAP/TUN (used for VMs):**
- **TAP/TUN**: Bridges kernel and userspace process
  - One end is a file descriptor that userspace programs (like QEMU) read/write
  - Used for VMs: hypervisor reads packets from TAP device
- **veth**: Connects two kernel network namespaces
  - Both ends are kernel devices (no userspace involved)
  - Used for containers: kernel-to-kernel forwarding
  - Lower overhead than TAP/TUN

**Why this matters:**
- Each container gets its own network stack
- No IP address conflicts between containers
- Container networking isolated from host
- Veth pairs provide the "bridge" between isolated container and host network

---

### MNT Namespace: Filesystem Isolation

**What it isolates:** Mount points (what filesystems are mounted where)

```
Host Filesystem:
/
â”œâ”€ /bin
â”œâ”€ /etc
â”œâ”€ /home
â””â”€ /var

Container Filesystem (MNT namespace):
/  â† Container's root (actually /var/lib/containers/xyz on host)
â”œâ”€ /bin
â”œâ”€ /etc  â† Container's own /etc!
â”œâ”€ /app
â””â”€ /tmp
```

**Key properties:**
- Container has its own **mount table**
- Mounting a filesystem inside container doesn't affect host
- Container's "/" is actually a subdirectory on host
- Enables **chroot** on steroids

**Why this matters:**
- Container sees only its own files
- Can't access host's /etc, /home, etc. (unless explicitly mounted)
- Basis for container image filesystem isolation

---

### UTS Namespace: Hostname Isolation

**UTS** = **UNIX Time-Sharing** (historical name from early UNIX systems)

**What it isolates:** Hostname and domain name

```
Host:
$ hostname
datacenter-node-01.example.com

Container:
$ hostname
web-container-abc123
```

**Key properties:**
- Simple but important: each container can have its own hostname
- Useful for distributed systems (service discovery uses hostname)

---

### IPC Namespace: Inter-Process Communication Isolation

**What it isolates:** System V IPC objects, POSIX message queues

**IPC mechanisms isolated:**
- Shared memory segments
- Semaphores
- Message queues

**Why this matters:**
- Prevents processes in different containers from communicating via IPC
- Security: container can't spy on host's shared memory

---

### USER Namespace: User ID Mapping

**What it isolates:** User IDs and group IDs (UIDs/GIDs)

**The magic:** Root inside container is **not** root outside!

```
Outside Container (host):
UID 0:     root (god mode)
UID 1000:  alice
UID 100000: (mapped to container's UID 0)

Inside Container:
UID 0:     root  â† Appears as root! (actually UID 100000 on host)
UID 1:     nginx
```

**Key properties:**
- **UID mapping**: Container's UID 0 maps to unprivileged UID on host
- Even if container process thinks it's root, it's not root on host
- Critical security feature

**Why this matters:**
- Container escape: even if attacker becomes root in container, they're not root on host
- **Rootless containers** rely on this (run containers as non-root user)

---

### CGROUP Namespace: Control Group View Isolation

**What it isolates:** View of the cgroup hierarchy

**Purpose:** Container sees itself at root of cgroup tree

```
Host's view:
/sys/fs/cgroup/
â”œâ”€ cpu/
â”‚  â”œâ”€ docker/
â”‚  â”‚  â””â”€ container123/  â† Container's cgroup
â”‚  â””â”€ system.slice/

Container's view:
/sys/fs/cgroup/
â””â”€ cpu/  â† Appears as root!
```

**Why this matters:**
- Container can't see or modify other containers' cgroups
- Security: prevents container from adjusting resource limits of others

---

## Part 2: cgroups - Resource Control

### What are cgroups?

**Control Groups (cgroups)** limit and account for resource usage of process groups.

**Namespaces answer:** "What can you see?"
**cgroups answer:** "How much can you use?"

### cgroups Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cgroup Hierarchy                                        â”‚
â”‚                                                          â”‚
â”‚ Root cgroup                                             â”‚
â”‚  â”œâ”€ /system.slice (system services)                    â”‚
â”‚  â”œâ”€ /user.slice (user sessions)                        â”‚
â”‚  â””â”€ /docker                                             â”‚
â”‚      â”œâ”€ /container1  â† 2 CPU cores, 4GB RAM max       â”‚
â”‚      â””â”€ /container2  â† 1 CPU core, 2GB RAM max        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Each cgroup can limit:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESOURCE         â”‚ WHAT IT CONTROLS                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cpu              â”‚ CPU time (shares, quotas)           â”‚
â”‚ memory           â”‚ RAM usage (limits, OOM behavior)    â”‚
â”‚ blkio            â”‚ Block device I/O (disk bandwidth)   â”‚
â”‚ cpuset           â”‚ CPU/NUMA node pinning               â”‚
â”‚ devices          â”‚ Device access (which devices)       â”‚
â”‚ freezer          â”‚ Suspend/resume processes            â”‚
â”‚ net_cls/net_prio â”‚ Network traffic classification      â”‚
â”‚ pids             â”‚ Number of processes (fork bomb)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### cgroups v1 vs v2

**cgroups v1** (legacy):
- Multiple hierarchies (one per resource type)
- Complex to manage
- Inconsistent semantics across controllers

**cgroups v2** (modern, default since systemd 226):
- **Single unified hierarchy**
- Consistent semantics
- Better resource distribution
- **Preferred for new deployments**

```
cgroups v1 (multiple hierarchies):
/sys/fs/cgroup/cpu/docker/container1
/sys/fs/cgroup/memory/docker/container1
/sys/fs/cgroup/blkio/docker/container1

cgroups v2 (unified hierarchy):
/sys/fs/cgroup/docker/container1
  â”œâ”€ cpu.max (CPU limit)
  â”œâ”€ memory.max (RAM limit)
  â””â”€ io.max (I/O limit)
```

---

### CPU Limiting Example

**Scenario:** Limit container to 50% of one CPU core

**cgroups v2:**
```bash
# Create cgroup
mkdir /sys/fs/cgroup/mycontainer

# Set CPU quota: 50000 microseconds out of every 100000 (50%)
echo "50000 100000" > /sys/fs/cgroup/mycontainer/cpu.max

# Add process to cgroup
echo $PID > /sys/fs/cgroup/mycontainer/cgroup.procs
```

**What happens:**
- Process runs normally until it uses 50% of a core
- Kernel **throttles** the process for remainder of 100ms period
- Next period (100ms later), process can run again

**Visible effect:**
```bash
# Without cgroup
$ stress --cpu 1
# CPU usage: 100%

# With cgroup (50% limit)
$ stress --cpu 1
# CPU usage: 50%  â† Throttled!
```

---

### Memory Limiting Example

**Scenario:** Limit container to 512MB RAM

```bash
# Set memory limit
echo "512M" > /sys/fs/cgroup/mycontainer/memory.max

# What happens when limit is exceeded?
# Depends on memory.oom.group setting:
# - Kill the process (OOM kill)
# - Or throttle by forcing disk swapping (if swap enabled)
```

**OOM Kill behavior:**
```bash
# Container tries to allocate 600MB when limited to 512MB
# Kernel log:
[ 1234.567] Memory cgroup out of memory: Killed process 5678 (myapp)
[ 1234.568] Task in /docker/container1 killed as a result of limit
```

**Critical for containers:** Prevents one container from consuming all RAM and starving others.

---

## Part 3: How Containers Use These Primitives

### Container = Namespaces + cgroups

```
Container Creation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Create namespaces:                                 â”‚
â”‚    - PID namespace   (process isolation)              â”‚
â”‚    - NET namespace   (network isolation)              â”‚
â”‚    - MNT namespace   (filesystem isolation)           â”‚
â”‚    - UTS namespace   (hostname)                       â”‚
â”‚    - IPC namespace   (IPC isolation)                  â”‚
â”‚    - USER namespace  (UID mapping) - optional         â”‚
â”‚    - CGROUP namespace (cgroup view isolation)         â”‚
â”‚                                                        â”‚
â”‚ 2. Create cgroup:                                     â”‚
â”‚    /sys/fs/cgroup/docker/container_xyz                â”‚
â”‚                                                        â”‚
â”‚ 3. Set resource limits in cgroup:                     â”‚
â”‚    - cpu.max = 200000 100000  (2 cores)              â”‚
â”‚    - memory.max = 4G                                  â”‚
â”‚    - pids.max = 512                                   â”‚
â”‚                                                        â”‚
â”‚ 4. Place processes in:                                â”‚
â”‚    - Namespaces (unshare() syscall)                   â”‚
â”‚    - cgroup (echo $PID > cgroup.procs)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Simple Container (Conceptually)

```bash
#!/bin/bash
# Simplified container creation (pseudo-code)

# 1. Create namespaces
unshare --pid --net --mount --uts --ipc \
  # 2. Set up cgroup
  cgcreate -g cpu,memory:mycontainer && \
  cgset -r cpu.max="100000 100000" mycontainer && \
  cgset -r memory.max=512M mycontainer && \

  # 3. Run process in namespace + cgroup
  cgexec -g cpu,memory:mycontainer \
    chroot /var/lib/containers/myapp /bin/bash
```

**What just happened:**
- `unshare`: Created isolated namespaces
- `cgcreate/cgset`: Set up resource limits
- `chroot`: Changed root filesystem
- Process now runs in its own world with resource limits!

---

## Part 4: Security Boundaries and Limitations

### What Containers DO Isolate

âœ… **Process visibility** - Can't see other containers' processes
âœ… **Filesystem** - Can't access other containers' files
âœ… **Network** - Own IP addresses, ports, routing
âœ… **Resource usage** - CPU/memory limits enforced
âœ… **Hostname** - Own hostname/domain name

### What Containers DON'T Isolate

âŒ **Kernel** - All containers share the same Linux kernel!
âŒ **System calls** - Containers can make any syscall (unless restricted)
âŒ **Kernel vulnerabilities** - Kernel exploit affects ALL containers
âŒ **Hardware** - No hardware isolation (no EPT, no VMX)
âŒ **Side channels** - Spectre/Meltdown affect all containers

### Critical Security Implications

**Container escape is easier than VM escape:**

```
VM Escape:
â”œâ”€ Must break out of VMX non-root mode
â”œâ”€ EPT protects memory
â”œâ”€ IOMMU protects devices
â””â”€ Extremely difficult (hardware barriers)

Container Escape:
â”œâ”€ Just need kernel vulnerability
â”œâ”€ Or misconfigured capability/seccomp
â”œâ”€ Shared kernel = shared attack surface
â””â”€ Much easier (software barriers only)
```

**Example vulnerabilities that don't affect VMs:**
- **Dirty COW** (CVE-2016-5195) - Kernel memory corruption
- **runc escape** (CVE-2019-5736) - Container runtime exploit
- **Kubernetes privilege escalation** - Misconfiguration attacks

**When VMs are better:**
- **Multi-tenant systems** (untrusted code)
- **Strong isolation required** (financial, healthcare)
- **Different kernel versions needed** (legacy apps)

**When containers are acceptable:**
- **Trusted code** (your own microservices)
- **Same trust domain** (internal apps)
- **Orchestration/density matters** (Kubernetes)

---

## Part 5: Comparison to Virtual Machine Isolation

### Architecture Comparison

```
VIRTUAL MACHINE ISOLATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VM 1                  VM 2                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ App         â”‚      â”‚ App         â”‚     â”‚
â”‚ â”‚ Guest OS    â”‚      â”‚ Guest OS    â”‚     â”‚ â† Separate kernels
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          VMX non-root mode                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Hypervisor (VMX root)            â”‚ â† Hardware boundary
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Hardware (CPU, RAM, NIC)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CONTAINER ISOLATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Container 1       Container 2             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚ App         â”‚  â”‚ App         â”‚         â”‚
â”‚ â”‚ (namespace) â”‚  â”‚ (namespace) â”‚         â”‚ â† Namespace boundary
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Shared Linux Kernel                   â”‚ â† Software boundary only!
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Hardware (CPU, RAM, NIC)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC             â”‚ CONTAINER    â”‚ VM           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Startup time       â”‚ Milliseconds â”‚ Seconds      â”‚
â”‚ Memory overhead    â”‚ ~10 MB       â”‚ ~100 MB+     â”‚
â”‚ Disk overhead      â”‚ ~50 MB       â”‚ ~1 GB+       â”‚
â”‚ CPU overhead       â”‚ <1%          â”‚ 2-5%         â”‚
â”‚ I/O performance    â”‚ Near-native  â”‚ Good (90-95%)â”‚
â”‚ Density (per host) â”‚ 100s-1000s   â”‚ 10s-100s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Security Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SECURITY ASPECT        â”‚ CONTAINER    â”‚ VM           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Kernel isolation       â”‚ âŒ Shared    â”‚ âœ… Separate  â”‚
â”‚ Hardware isolation     â”‚ âŒ None      â”‚ âœ… EPT/IOMMU â”‚
â”‚ Escape difficulty      â”‚ Medium       â”‚ Very Hard    â”‚
â”‚ Multi-tenancy safe?    â”‚ âš ï¸  With careâ”‚ âœ… Yes       â”‚
â”‚ Trust boundary         â”‚ Software     â”‚ Hardware     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference

### Namespace Types

| Namespace | Isolates | Created With |
|-----------|----------|--------------|
| PID | Process IDs | `unshare --pid` |
| NET | Network stack | `unshare --net` |
| MNT | Mount points | `unshare --mount` |
| UTS | Hostname | `unshare --uts` |
| IPC | IPC resources | `unshare --ipc` |
| USER | UID/GID mapping | `unshare --user` |
| CGROUP | cgroup view | `unshare --cgroup` |

### cgroups v2 Limits

| Resource | Control File | Example |
|----------|--------------|---------|
| CPU | `cpu.max` | `100000 100000` (1 core) |
| Memory | `memory.max` | `512M` |
| I/O | `io.max` | Device-specific |
| PIDs | `pids.max` | `512` |

### Key Commands

```bash
# List namespaces for process
ls -la /proc/$PID/ns/

# Create all namespaces
unshare --pid --net --mount --uts --ipc --user --fork /bin/bash

# View cgroup membership
cat /proc/$PID/cgroup

# Show cgroup resource usage
cat /sys/fs/cgroup/docker/container1/cpu.stat
```

---

## What You've Learned

âœ… **Namespaces provide isolation** - 7 types isolating different resources
âœ… **cgroups provide resource limits** - CPU, memory, I/O, PIDs
âœ… **Containers = namespaces + cgroups** - Software-based isolation
âœ… **Shared kernel** - All containers run on same kernel
âœ… **Security tradeoffs** - Faster and lighter than VMs, but weaker isolation
âœ… **Use case alignment** - Containers for trusted code, VMs for strong isolation

---

## Hands-On Resources

> ğŸ’¡ **Want more?** This section shows the most essential resources for this topic.
> For a comprehensive list of tutorials, code repositories, and tools across all container topics, see:
> **â†’ [Complete Container Learning Resources](../00_LEARNING_RESOURCES.md)** ğŸ“š

- **[Containers from Scratch](https://ericchiang.github.io/post/containers-from-scratch/)** - Build a minimal container runtime to understand namespaces and cgroups from first principles
- **[bocker](https://github.com/p8952/bocker)** - Docker implementation in ~100 lines of bash demonstrating the core primitives
- **[Linux Programmer's Manual](https://man7.org/linux/man-pages/man7/namespaces.7.html)** - Official documentation for namespaces and cgroups syscalls

---

## Next Steps

**Continue learning:**
â†’ [Union Filesystems](02_union_filesystems.md) - How container images work with layers
â†’ [Container vs VM Deep Dive](03_container_vs_vm.md) - When to use each

**Related topics:**
â†’ [The Ring-0 Problem](../../01_foundations/01_virtualization_basics/01_the_ring0_problem.md) - Why VMs need hardware support
â†’ [VM Exit Basics](../../01_foundations/01_virtualization_basics/03_vm_exit_basics.md) - Compare to container syscall overhead
